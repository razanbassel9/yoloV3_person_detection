{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f54678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "class MyYolo:\n",
    "    \"\"\"\n",
    "        Implements YOLOv3 object detection algorithm. This code is edited from https://pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/\n",
    "    \"\"\"\n",
    "    \n",
    "    # constants\n",
    "    NAMES_FILE = 'classes.names'\n",
    "    WEIGHTS_FILE = 'yolov3_custom_last.weights'\n",
    "    CFG_FILE = 'yolov3_custom.cfg'\n",
    "    \n",
    "    \n",
    "    def __init__(self, model_path, min_confidence=0.5, nms_thresh=0.3,\n",
    "                 object_names=None):\n",
    "        \"\"\"\n",
    "            - model_path (str): path to folder containing .names, .cfg, \n",
    "              and .weights files\n",
    "            - min_confidence (float): Minimum confidence to predict an object\n",
    "            - nms_thresh (float): Non-Maximum Suppression threshold to prevent\n",
    "              detection of multiple boxes for the same object\n",
    "            - object_names (list<str> or None): A list of object names to detect.\n",
    "              If None, all types of objects from NAMES_FILE will be detected\n",
    "        \"\"\"\n",
    "        \n",
    "        # min_confidence and nms_thresh\n",
    "        self.min_confidence = min_confidence\n",
    "        self.nms_thresh = nms_thresh\n",
    "        \n",
    "        # get labels and class_idx_filter\n",
    "        labelsPath = os.path.join(model_path, MyYolo.NAMES_FILE)\n",
    "        self.labels = open(labelsPath).read().strip().split(\"\\n\")\n",
    "        self.class_idx_filter = []\n",
    "        if object_names:\n",
    "            for name in object_names:\n",
    "                if name not in self.labels:\n",
    "                    raise ValueError('Unknown object \"{}\"'.format(name))\n",
    "                else:\n",
    "                    idx = self.labels.index(name)\n",
    "                    self.class_idx_filter.append(idx)\n",
    "\n",
    "        # generate random colors for classes\n",
    "        np.random.seed(42)\n",
    "        self.colors = np.random.randint(0, 255, size=(len(self.labels), 3), \n",
    "                                        dtype=\"uint8\")\n",
    "        \n",
    "        # paths to the YOLO weights and model configuration\n",
    "        weightsPath = os.path.join(model_path, MyYolo.WEIGHTS_FILE)\n",
    "        configPath = os.path.join(model_path, MyYolo.CFG_FILE)\n",
    "        \n",
    "        # load our YOLO object detector trained on COCO dataset (80 classes)\n",
    "        self.net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "    \n",
    "    \n",
    "    def predict(self, image, is_bgr=True):\n",
    "        \"\"\"\n",
    "            - image (numpy.ndarray): input image\n",
    "            - is_bgr: whether the input image is BGR. If False, the image\n",
    "              is assumed to be RGB\n",
    "            \n",
    "            - returns two values: \n",
    "                (1)   predictions (list<dict>): Each item is a dictionary\n",
    "                      that contains 3 keys: \"class_name\", \"box\", \"confidence\", \n",
    "                      where \"box\" is a list of [x, y, width, height]\n",
    "                (2)   output_image (numpy.ndarray): output image with\n",
    "                      predictions drawn\n",
    "        \"\"\"\n",
    "        (H, W) = image.shape[:2]\n",
    "        # determine only the *output* layer names that we need from YOLO\n",
    "        ln = [layer_name for layer_name in self.net.getUnconnectedOutLayersNames()]\n",
    "        # construct a blob from the input image and then perform a forward\n",
    "        # pass of the YOLO object detector, giving us our bounding boxes and\n",
    "        # associated probabilities\n",
    "        blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
    "            swapRB=is_bgr, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        layerOutputs = self.net.forward(ln)\n",
    "        \n",
    "        # initialize our lists of detected bounding boxes, confidences, and\n",
    "        # class IDs, respectively\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classIDs = []\n",
    "        \n",
    "        # loop over each of the layer outputs\n",
    "        for output in layerOutputs:\n",
    "            # loop over each of the detections\n",
    "            for detection in output:\n",
    "                # extract the class ID and confidence (i.e., probability) of\n",
    "                # the current object detection\n",
    "                # Note: detection contains: [xcenter, ycenter, width, height, \n",
    "                #                             probOfHasObject, ...scores...]\n",
    "                scores = detection[5:]\n",
    "                classID = np.argmax(scores)\n",
    "                confidence = scores[classID]\n",
    "                # select only names from class_filter (if given)\n",
    "                if self.class_idx_filter and classID not in self.class_idx_filter:\n",
    "                    continue\n",
    "                # filter out weak predictions by ensuring the detected\n",
    "                # probability is greater than the minimum probability\n",
    "                if confidence > self.min_confidence:\n",
    "                    # scale the bounding box coordinates back relative to the\n",
    "                    # size of the image, keeping in mind that YOLO actually\n",
    "                    # returns the center (x, y)-coordinates of the bounding\n",
    "                    # box followed by the boxes' width and height\n",
    "                    box = detection[0:4] * np.array([W, H, W, H])\n",
    "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                    # use the center (x, y)-coordinates to derive the top and\n",
    "                    # and left corner of the bounding box\n",
    "                    x = int(centerX - (width / 2))\n",
    "                    y = int(centerY - (height / 2))\n",
    "                    # update our list of bounding box coordinates, confidences,\n",
    "                    # and class IDs\n",
    "                    boxes.append([x, y, int(width), int(height)])\n",
    "                    confidences.append(float(confidence))\n",
    "                    classIDs.append(classID)\n",
    "                    \n",
    "        # apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "        # boxes\n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, self.min_confidence, \n",
    "                                self.nms_thresh)\n",
    "        \n",
    "        # ensure at least one detection exists\n",
    "        predictions = []\n",
    "        out_image = image.copy()\n",
    "        if len(idxs) > 0:\n",
    "            # loop over the indexes we are keeping\n",
    "            for i in idxs.flatten():\n",
    "                pred = {}\n",
    "                pred['box'] = boxes[i]\n",
    "                pred['class_name'] = self.labels[classIDs[i]]\n",
    "                pred['confidence'] = confidences[i]\n",
    "                predictions.append(pred)\n",
    "                # extract the bounding box coordinates\n",
    "                (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                (w, h) = (boxes[i][2], boxes[i][3])\n",
    "                # draw a bounding box rectangle and label on the image\n",
    "                color = [int(c) for c in self.colors[classIDs[i]]]\n",
    "                cv2.rectangle(out_image, (x, y), (x + w, y + h), color, 2)\n",
    "                text = \"{}: {:.4f}\".format(self.labels[classIDs[i]], confidences[i])\n",
    "                cv2.putText(out_image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, color, 2)\n",
    "        \n",
    "        # return predictions and output image\n",
    "        return predictions, out_image\n",
    "    \n",
    "    \n",
    "    def predict_from_cam(self):\n",
    "        \"\"\"\n",
    "            Start object detection from Web cam. Press 'q' to stop.\n",
    "        \"\"\"\n",
    "        \n",
    "        # define a video capture object\n",
    "        vid = cv2.VideoCapture(0)\n",
    "          \n",
    "        while(True):\n",
    "              \n",
    "            # Capture the video frame by frame\n",
    "            ret, frame = vid.read()\n",
    "            \n",
    "            # make predictions\n",
    "            preds, frame = self.predict(frame)\n",
    "          \n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('yolo', frame)\n",
    "              \n",
    "            # the 'q' button is set as the\n",
    "            # quitting button you may use any\n",
    "            # desired button of your choice\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "          \n",
    "        # After the loop release the cap object\n",
    "        vid.release()\n",
    "        # Destroy all the windows\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "    def predict_from_video(self, src_path, dst_path):\n",
    "        \"\"\"\n",
    "            Start object detection from Web cam. Press 'q' to stop.\n",
    "        \"\"\"\n",
    "        \n",
    "        # define a video capture object\n",
    "        vid = cv2.VideoCapture(src_path)\n",
    "        \n",
    "        # initialize writer\n",
    "        writer = None\n",
    "        \n",
    "        print('Processing video...')\n",
    "          \n",
    "        while(True):\n",
    "              \n",
    "            # Capture the video frame by frame\n",
    "            ret, frame = vid.read()\n",
    "            \n",
    "            # check end of video\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # make predictions\n",
    "            preds, frame = self.predict(frame)\n",
    "          \n",
    "            # check if the video writer is None\n",
    "            if writer is None:\n",
    "        \t\t# initialize our video writer\n",
    "                fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "                writer = cv2.VideoWriter(dst_path, fourcc, 30,\n",
    "        \t\t\t(frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "        \t# write the output frame to disk\n",
    "            writer.write(frame)\n",
    "          \n",
    "        # After the loop release the cap object and writer\n",
    "        vid.release()\n",
    "        writer.release()\n",
    "        \n",
    "        print('Video saved to \"{}'.format(dst_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
